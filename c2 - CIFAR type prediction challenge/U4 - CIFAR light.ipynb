{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:42.109620Z",
     "start_time": "2018-05-19T14:11:41.352270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 3, 32, 32) float32\n",
      "(6000,) int64\n",
      "(300, 3, 32, 32) float32\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvjSOVpIesxgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1075a3748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "with np.load('prediction-challenge-02-data.npz') as fh:\n",
    "    data_x = fh['data_x']\n",
    "    data_y = fh['data_y']\n",
    "    test_x = fh['test_x']\n",
    "\n",
    "# TRAINING DATA: INPUT (x) AND OUTPUT (y)\n",
    "# 1. INDEX: IMAGE SERIAL NUMBER (6000)\n",
    "# 2. INDEX: COLOR CHANNELS (3)\n",
    "# 3/4. INDEX: PIXEL VALUE (32 x 32)\n",
    "print(data_x.shape, data_x.dtype)\n",
    "print(data_y.shape, data_y.dtype)\n",
    "\n",
    "# TEST DATA: INPUT (x) ONLY\n",
    "print(test_x.shape, test_x.dtype)\n",
    "\n",
    "plt.imshow(data_x[4999].transpose((1,2,0)))\n",
    "plt.title(data_y[4999])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:42.114797Z",
     "start_time": "2018-05-19T14:11:42.111327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 2, 0, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:42.120774Z",
     "start_time": "2018-05-19T14:11:42.116381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([164, 183, 153]), array([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(data_y[:500],bins=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:42.126870Z",
     "start_time": "2018-05-19T14:11:42.122327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1836, 1817, 1847]), array([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(data_y[500:],bins=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:42.132805Z",
     "start_time": "2018-05-19T14:11:42.128283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 22,  39,  48, ...,  61,  49,  28],\n",
       "        [ 24,  45,  58, ...,  74,  46,  25],\n",
       "        [ 41,  64,  69, ...,  92,  48,  36],\n",
       "        ..., \n",
       "        [136, 129, 153, ...,  95,  96,  91],\n",
       "        [140, 127, 137, ..., 120, 118,  96],\n",
       "        [128, 126, 126, ..., 124, 126,  61]],\n",
       "\n",
       "       [[110, 118, 119, ..., 126, 123, 113],\n",
       "        [109, 114, 115, ..., 123, 111, 101],\n",
       "        [114, 114, 106, ..., 125, 105, 103],\n",
       "        ..., \n",
       "        [ 96,  90, 120, ...,  76,  78,  72],\n",
       "        [100,  88, 105, ...,  98,  98,  78],\n",
       "        [ 87,  86,  93, ...,  99, 104,  44]],\n",
       "\n",
       "       [[200, 200, 193, ..., 193, 193, 205],\n",
       "        [194, 187, 182, ..., 177, 176, 184],\n",
       "        [188, 170, 157, ..., 163, 164, 176],\n",
       "        ..., \n",
       "        [ 60,  54,  83, ...,  62,  68,  67],\n",
       "        [ 67,  54,  67, ...,  78,  82,  68],\n",
       "        [ 58,  54,  54, ...,  72,  83,  31]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_x[2]*255).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:42.295614Z",
     "start_time": "2018-05-19T14:11:42.134199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "torch.get_num_threads() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:42.303547Z",
     "start_time": "2018-05-19T14:11:42.297208Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "stochastic_transform = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "     transforms.RandomRotation(15),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.ColorJitter(brightness=0.15,contrast=0.8,hue=0.1,saturation=0.8),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:42.352771Z",
     "start_time": "2018-05-19T14:11:42.305293Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CIFARdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, fp, transform, dset=\"train\"):\n",
    "        VAL_SIZE = 500\n",
    "        self.transform = transform\n",
    "        with np.load(fp) as fh:\n",
    "            if dset==\"train\":\n",
    "                self.data_x = (fh['data_x'][VAL_SIZE:]*255).astype('uint8')\n",
    "                self.data_y = fh['data_y'][VAL_SIZE:]\n",
    "                assert len(self.data_x) == len(self.data_y)\n",
    "            elif dset==\"test\":\n",
    "                self.data_x = (fh['data_x'][:VAL_SIZE]*255).astype('uint8')\n",
    "                self.data_y = fh['data_y'][:VAL_SIZE]\n",
    "                assert len(self.data_x) == len(self.data_y)\n",
    "            elif dset==\"pred\":\n",
    "                self.data_x = (fh['test_x']*255).astype('uint8')\n",
    "                self.data_y = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = self.data_x[i].transpose(1,2,0)\n",
    "        if self.data_y is None:\n",
    "            image = self.transform(image)\n",
    "            return image\n",
    "        label = self.data_y[i]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = (image, label)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:43.034672Z",
     "start_time": "2018-05-19T14:11:42.354889Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp = 'prediction-challenge-02-data.npz'\n",
    "train_dataset = CIFARdataset(fp,stochastic_transform,dset=\"train\")\n",
    "test_dataset = CIFARdataset(fp,transform,dset=\"test\")\n",
    "pred_dataset = CIFARdataset(fp,transform,dset=\"pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:43.185412Z",
     "start_time": "2018-05-19T14:11:43.036393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsGQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ff96160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train_dataset[0][0].numpy()\n",
    "plt.imshow(x.transpose((1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:43.192062Z",
     "start_time": "2018-05-19T14:11:43.186979Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=8, \n",
    "                                           shuffle=True,\n",
    "                                           **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=8,\n",
    "                                          shuffle=False,\n",
    "                                          **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:43.528857Z",
     "start_time": "2018-05-19T14:11:43.194084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(3, 3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 3 * 3, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "      \n",
    "        \n",
    "        x = x.view(-1, 32 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(3, 3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 3 * 3, 42)\n",
    "        self.fc2 = nn.Linear(42, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        #print(x.size())\n",
    "      \n",
    "        \n",
    "        x = x.view(-1, 32 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 1 * 1, 24)\n",
    "        self.fc2 = nn.Linear(24, 3)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(3, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        #print(x.size())\n",
    "      \n",
    "        \n",
    "        x = x.view(-1, 64 * 1 * 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net1 = Net()\n",
    "\n",
    "net2 = Net2()\n",
    "\n",
    "net3 = Net3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:43.588430Z",
     "start_time": "2018-05-19T14:11:43.530572Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train(model,optimizer,epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))     \n",
    "            \n",
    "def evaluate(model,optimizer):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            \n",
    "            val_loss += nn.CrossEntropyLoss(size_average=False)(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        val_loss /= len(test_loader.dataset)\n",
    "        print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            val_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:11:43.625206Z",
     "start_time": "2018-05-19T14:11:43.590514Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# criterion_train = nn.CrossEntropyLoss()\n",
    "# criterion_test = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer1 = optim.Adam(net1.parameters()) #SGD(model.parameters(), lr=0.008, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T16:30:27.255931Z",
     "start_time": "2018-05-19T14:49:48.760508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/5500 (0%)]\tLoss: 0.120953\n",
      "Train Epoch: 1 [1600/5500 (29%)]\tLoss: 0.608870\n",
      "Train Epoch: 1 [3200/5500 (58%)]\tLoss: 0.185919\n",
      "Train Epoch: 1 [4800/5500 (87%)]\tLoss: 0.656778\n",
      "Validation set: Average loss: 0.5305, Accuracy: 380/500 (76%)\n",
      "\n",
      "Train Epoch: 2 [0/5500 (0%)]\tLoss: 0.290907\n",
      "Train Epoch: 2 [1600/5500 (29%)]\tLoss: 0.616487\n",
      "Train Epoch: 2 [3200/5500 (58%)]\tLoss: 1.499288\n",
      "Train Epoch: 2 [4800/5500 (87%)]\tLoss: 0.489130\n",
      "Validation set: Average loss: 0.6902, Accuracy: 367/500 (73%)\n",
      "\n",
      "Train Epoch: 3 [0/5500 (0%)]\tLoss: 0.459042\n",
      "Train Epoch: 3 [1600/5500 (29%)]\tLoss: 0.580483\n",
      "Train Epoch: 3 [3200/5500 (58%)]\tLoss: 0.590616\n",
      "Train Epoch: 3 [4800/5500 (87%)]\tLoss: 0.428472\n",
      "Validation set: Average loss: 0.5710, Accuracy: 374/500 (74%)\n",
      "\n",
      "Train Epoch: 4 [0/5500 (0%)]\tLoss: 0.304985\n",
      "Train Epoch: 4 [1600/5500 (29%)]\tLoss: 0.446098\n",
      "Train Epoch: 4 [3200/5500 (58%)]\tLoss: 0.744040\n",
      "Train Epoch: 4 [4800/5500 (87%)]\tLoss: 0.451343\n",
      "Validation set: Average loss: 0.5604, Accuracy: 380/500 (76%)\n",
      "\n",
      "Train Epoch: 5 [0/5500 (0%)]\tLoss: 0.302652\n",
      "Train Epoch: 5 [1600/5500 (29%)]\tLoss: 0.310660\n",
      "Train Epoch: 5 [3200/5500 (58%)]\tLoss: 0.421615\n",
      "Train Epoch: 5 [4800/5500 (87%)]\tLoss: 0.316725\n",
      "Validation set: Average loss: 0.5317, Accuracy: 386/500 (77%)\n",
      "\n",
      "Train Epoch: 6 [0/5500 (0%)]\tLoss: 0.368242\n",
      "Train Epoch: 6 [1600/5500 (29%)]\tLoss: 0.644017\n",
      "Train Epoch: 6 [3200/5500 (58%)]\tLoss: 0.697755\n",
      "Train Epoch: 6 [4800/5500 (87%)]\tLoss: 0.864232\n",
      "Validation set: Average loss: 0.5123, Accuracy: 395/500 (79%)\n",
      "\n",
      "Train Epoch: 7 [0/5500 (0%)]\tLoss: 1.020399\n",
      "Train Epoch: 7 [1600/5500 (29%)]\tLoss: 0.442477\n",
      "Train Epoch: 7 [3200/5500 (58%)]\tLoss: 0.995158\n",
      "Train Epoch: 7 [4800/5500 (87%)]\tLoss: 0.166351\n",
      "Validation set: Average loss: 0.5509, Accuracy: 371/500 (74%)\n",
      "\n",
      "Train Epoch: 8 [0/5500 (0%)]\tLoss: 0.610887\n",
      "Train Epoch: 8 [1600/5500 (29%)]\tLoss: 0.446542\n",
      "Train Epoch: 8 [3200/5500 (58%)]\tLoss: 0.776629\n",
      "Train Epoch: 8 [4800/5500 (87%)]\tLoss: 0.379459\n",
      "Validation set: Average loss: 0.5038, Accuracy: 392/500 (78%)\n",
      "\n",
      "Train Epoch: 9 [0/5500 (0%)]\tLoss: 0.451469\n",
      "Train Epoch: 9 [1600/5500 (29%)]\tLoss: 0.334168\n",
      "Train Epoch: 9 [3200/5500 (58%)]\tLoss: 0.112985\n",
      "Train Epoch: 9 [4800/5500 (87%)]\tLoss: 0.478865\n",
      "Validation set: Average loss: 0.5218, Accuracy: 390/500 (78%)\n",
      "\n",
      "Train Epoch: 10 [0/5500 (0%)]\tLoss: 0.412522\n",
      "Train Epoch: 10 [1600/5500 (29%)]\tLoss: 0.438114\n",
      "Train Epoch: 10 [3200/5500 (58%)]\tLoss: 0.984742\n",
      "Train Epoch: 10 [4800/5500 (87%)]\tLoss: 0.602820\n",
      "Validation set: Average loss: 0.5142, Accuracy: 386/500 (77%)\n",
      "\n",
      "Train Epoch: 11 [0/5500 (0%)]\tLoss: 0.208035\n",
      "Train Epoch: 11 [1600/5500 (29%)]\tLoss: 0.378337\n",
      "Train Epoch: 11 [3200/5500 (58%)]\tLoss: 0.276783\n",
      "Train Epoch: 11 [4800/5500 (87%)]\tLoss: 0.596738\n",
      "Validation set: Average loss: 0.5080, Accuracy: 401/500 (80%)\n",
      "\n",
      "Train Epoch: 12 [0/5500 (0%)]\tLoss: 0.287359\n",
      "Train Epoch: 12 [1600/5500 (29%)]\tLoss: 1.066770\n",
      "Train Epoch: 12 [3200/5500 (58%)]\tLoss: 0.287530\n",
      "Train Epoch: 12 [4800/5500 (87%)]\tLoss: 0.556564\n",
      "Validation set: Average loss: 0.5458, Accuracy: 390/500 (78%)\n",
      "\n",
      "Train Epoch: 13 [0/5500 (0%)]\tLoss: 0.296890\n",
      "Train Epoch: 13 [1600/5500 (29%)]\tLoss: 0.374657\n",
      "Train Epoch: 13 [3200/5500 (58%)]\tLoss: 0.295678\n",
      "Train Epoch: 13 [4800/5500 (87%)]\tLoss: 0.303277\n",
      "Validation set: Average loss: 0.5536, Accuracy: 391/500 (78%)\n",
      "\n",
      "Train Epoch: 14 [0/5500 (0%)]\tLoss: 0.430398\n",
      "Train Epoch: 14 [1600/5500 (29%)]\tLoss: 0.463005\n",
      "Train Epoch: 14 [3200/5500 (58%)]\tLoss: 0.399661\n",
      "Train Epoch: 14 [4800/5500 (87%)]\tLoss: 0.391489\n",
      "Validation set: Average loss: 0.5855, Accuracy: 391/500 (78%)\n",
      "\n",
      "Train Epoch: 15 [0/5500 (0%)]\tLoss: 0.205951\n",
      "Train Epoch: 15 [1600/5500 (29%)]\tLoss: 0.481919\n",
      "Train Epoch: 15 [3200/5500 (58%)]\tLoss: 0.382007\n",
      "Train Epoch: 15 [4800/5500 (87%)]\tLoss: 0.607424\n",
      "Validation set: Average loss: 0.5530, Accuracy: 391/500 (78%)\n",
      "\n",
      "Train Epoch: 16 [0/5500 (0%)]\tLoss: 0.677963\n",
      "Train Epoch: 16 [1600/5500 (29%)]\tLoss: 0.401376\n",
      "Train Epoch: 16 [3200/5500 (58%)]\tLoss: 0.337172\n",
      "Train Epoch: 16 [4800/5500 (87%)]\tLoss: 0.297185\n",
      "Validation set: Average loss: 0.5604, Accuracy: 392/500 (78%)\n",
      "\n",
      "Train Epoch: 17 [0/5500 (0%)]\tLoss: 0.185094\n",
      "Train Epoch: 17 [1600/5500 (29%)]\tLoss: 0.485640\n",
      "Train Epoch: 17 [3200/5500 (58%)]\tLoss: 0.415303\n",
      "Train Epoch: 17 [4800/5500 (87%)]\tLoss: 0.407536\n",
      "Validation set: Average loss: 0.5720, Accuracy: 386/500 (77%)\n",
      "\n",
      "Train Epoch: 18 [0/5500 (0%)]\tLoss: 0.433221\n",
      "Train Epoch: 18 [1600/5500 (29%)]\tLoss: 0.222469\n",
      "Train Epoch: 18 [3200/5500 (58%)]\tLoss: 0.382233\n",
      "Train Epoch: 18 [4800/5500 (87%)]\tLoss: 0.330156\n",
      "Validation set: Average loss: 0.5291, Accuracy: 393/500 (78%)\n",
      "\n",
      "Train Epoch: 19 [0/5500 (0%)]\tLoss: 0.355278\n",
      "Train Epoch: 19 [1600/5500 (29%)]\tLoss: 0.545635\n",
      "Train Epoch: 19 [3200/5500 (58%)]\tLoss: 0.162959\n",
      "Train Epoch: 19 [4800/5500 (87%)]\tLoss: 0.561419\n",
      "Validation set: Average loss: 0.5649, Accuracy: 391/500 (78%)\n",
      "\n",
      "Train Epoch: 20 [0/5500 (0%)]\tLoss: 0.258627\n",
      "Train Epoch: 20 [1600/5500 (29%)]\tLoss: 0.022962\n",
      "Train Epoch: 20 [3200/5500 (58%)]\tLoss: 0.231760\n",
      "Train Epoch: 20 [4800/5500 (87%)]\tLoss: 0.417586\n",
      "Validation set: Average loss: 0.5071, Accuracy: 407/500 (81%)\n",
      "\n",
      "Train Epoch: 21 [0/5500 (0%)]\tLoss: 0.292818\n",
      "Train Epoch: 21 [1600/5500 (29%)]\tLoss: 0.371180\n",
      "Train Epoch: 21 [3200/5500 (58%)]\tLoss: 0.669522\n",
      "Train Epoch: 21 [4800/5500 (87%)]\tLoss: 0.174067\n",
      "Validation set: Average loss: 0.5191, Accuracy: 398/500 (79%)\n",
      "\n",
      "Train Epoch: 22 [0/5500 (0%)]\tLoss: 0.218023\n",
      "Train Epoch: 22 [1600/5500 (29%)]\tLoss: 0.496116\n",
      "Train Epoch: 22 [3200/5500 (58%)]\tLoss: 0.406579\n",
      "Train Epoch: 22 [4800/5500 (87%)]\tLoss: 0.319551\n",
      "Validation set: Average loss: 0.5441, Accuracy: 385/500 (77%)\n",
      "\n",
      "Train Epoch: 23 [0/5500 (0%)]\tLoss: 0.612058\n",
      "Train Epoch: 23 [1600/5500 (29%)]\tLoss: 0.621967\n",
      "Train Epoch: 23 [3200/5500 (58%)]\tLoss: 0.609664\n",
      "Train Epoch: 23 [4800/5500 (87%)]\tLoss: 0.839113\n",
      "Validation set: Average loss: 0.6247, Accuracy: 398/500 (79%)\n",
      "\n",
      "Train Epoch: 24 [0/5500 (0%)]\tLoss: 0.255481\n",
      "Train Epoch: 24 [1600/5500 (29%)]\tLoss: 0.548520\n",
      "Train Epoch: 24 [3200/5500 (58%)]\tLoss: 0.654676\n",
      "Train Epoch: 24 [4800/5500 (87%)]\tLoss: 0.543333\n",
      "Validation set: Average loss: 0.5857, Accuracy: 369/500 (73%)\n",
      "\n",
      "Train Epoch: 25 [0/5500 (0%)]\tLoss: 0.363885\n",
      "Train Epoch: 25 [1600/5500 (29%)]\tLoss: 0.190212\n",
      "Train Epoch: 25 [3200/5500 (58%)]\tLoss: 0.442382\n",
      "Train Epoch: 25 [4800/5500 (87%)]\tLoss: 0.513291\n",
      "Validation set: Average loss: 0.5454, Accuracy: 393/500 (78%)\n",
      "\n",
      "Train Epoch: 26 [0/5500 (0%)]\tLoss: 0.484012\n",
      "Train Epoch: 26 [1600/5500 (29%)]\tLoss: 0.407069\n",
      "Train Epoch: 26 [3200/5500 (58%)]\tLoss: 0.116369\n",
      "Train Epoch: 26 [4800/5500 (87%)]\tLoss: 0.752275\n",
      "Validation set: Average loss: 0.6193, Accuracy: 391/500 (78%)\n",
      "\n",
      "Train Epoch: 27 [0/5500 (0%)]\tLoss: 0.371517\n",
      "Train Epoch: 27 [1600/5500 (29%)]\tLoss: 0.629721\n",
      "Train Epoch: 27 [3200/5500 (58%)]\tLoss: 0.283441\n",
      "Train Epoch: 27 [4800/5500 (87%)]\tLoss: 0.311877\n",
      "Validation set: Average loss: 0.5786, Accuracy: 391/500 (78%)\n",
      "\n",
      "Train Epoch: 28 [0/5500 (0%)]\tLoss: 0.122454\n",
      "Train Epoch: 28 [1600/5500 (29%)]\tLoss: 0.283715\n",
      "Train Epoch: 28 [3200/5500 (58%)]\tLoss: 0.710914\n",
      "Train Epoch: 28 [4800/5500 (87%)]\tLoss: 0.620317\n",
      "Validation set: Average loss: 0.5016, Accuracy: 395/500 (79%)\n",
      "\n",
      "Train Epoch: 29 [0/5500 (0%)]\tLoss: 0.587213\n",
      "Train Epoch: 29 [1600/5500 (29%)]\tLoss: 0.547515\n",
      "Train Epoch: 29 [3200/5500 (58%)]\tLoss: 0.384533\n",
      "Train Epoch: 29 [4800/5500 (87%)]\tLoss: 0.496554\n",
      "Validation set: Average loss: 0.5242, Accuracy: 399/500 (79%)\n",
      "\n",
      "Train Epoch: 30 [0/5500 (0%)]\tLoss: 0.300364\n",
      "Train Epoch: 30 [1600/5500 (29%)]\tLoss: 0.342619\n",
      "Train Epoch: 30 [3200/5500 (58%)]\tLoss: 0.117177\n",
      "Train Epoch: 30 [4800/5500 (87%)]\tLoss: 1.020601\n",
      "Validation set: Average loss: 0.5737, Accuracy: 385/500 (77%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(net1,optimizer1, epoch)\n",
    "    evaluate(net1,optimizer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:19:16.502077Z",
     "start_time": "2018-05-19T14:19:16.499379Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer2 = optim.Adam(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:25:16.405390Z",
     "start_time": "2018-05-19T14:19:16.503617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/5500 (0%)]\tLoss: 1.105009\n",
      "Train Epoch: 1 [1600/5500 (29%)]\tLoss: 1.178339\n",
      "Train Epoch: 1 [3200/5500 (58%)]\tLoss: 0.813777\n",
      "Train Epoch: 1 [4800/5500 (87%)]\tLoss: 0.701552\n",
      "Validation set: Average loss: 0.8881, Accuracy: 284/500 (56%)\n",
      "\n",
      "Train Epoch: 2 [0/5500 (0%)]\tLoss: 1.147110\n",
      "Train Epoch: 2 [1600/5500 (29%)]\tLoss: 0.937995\n",
      "Train Epoch: 2 [3200/5500 (58%)]\tLoss: 1.047457\n",
      "Train Epoch: 2 [4800/5500 (87%)]\tLoss: 0.595281\n",
      "Validation set: Average loss: 0.8486, Accuracy: 298/500 (59%)\n",
      "\n",
      "Train Epoch: 3 [0/5500 (0%)]\tLoss: 0.646806\n",
      "Train Epoch: 3 [1600/5500 (29%)]\tLoss: 0.666661\n",
      "Train Epoch: 3 [3200/5500 (58%)]\tLoss: 0.729717\n",
      "Train Epoch: 3 [4800/5500 (87%)]\tLoss: 0.636446\n",
      "Validation set: Average loss: 0.7918, Accuracy: 299/500 (59%)\n",
      "\n",
      "Train Epoch: 4 [0/5500 (0%)]\tLoss: 0.872458\n",
      "Train Epoch: 4 [1600/5500 (29%)]\tLoss: 0.841664\n",
      "Train Epoch: 4 [3200/5500 (58%)]\tLoss: 0.538523\n",
      "Train Epoch: 4 [4800/5500 (87%)]\tLoss: 0.580528\n",
      "Validation set: Average loss: 0.7157, Accuracy: 315/500 (63%)\n",
      "\n",
      "Train Epoch: 5 [0/5500 (0%)]\tLoss: 0.566862\n",
      "Train Epoch: 5 [1600/5500 (29%)]\tLoss: 0.502866\n",
      "Train Epoch: 5 [3200/5500 (58%)]\tLoss: 0.453971\n",
      "Train Epoch: 5 [4800/5500 (87%)]\tLoss: 0.248921\n",
      "Validation set: Average loss: 0.7337, Accuracy: 321/500 (64%)\n",
      "\n",
      "Train Epoch: 6 [0/5500 (0%)]\tLoss: 0.408500\n",
      "Train Epoch: 6 [1600/5500 (29%)]\tLoss: 0.786310\n",
      "Train Epoch: 6 [3200/5500 (58%)]\tLoss: 0.765807\n",
      "Train Epoch: 6 [4800/5500 (87%)]\tLoss: 0.710016\n",
      "Validation set: Average loss: 0.7002, Accuracy: 338/500 (67%)\n",
      "\n",
      "Train Epoch: 7 [0/5500 (0%)]\tLoss: 0.851095\n",
      "Train Epoch: 7 [1600/5500 (29%)]\tLoss: 0.643223\n",
      "Train Epoch: 7 [3200/5500 (58%)]\tLoss: 0.538550\n",
      "Train Epoch: 7 [4800/5500 (87%)]\tLoss: 0.607590\n",
      "Validation set: Average loss: 0.7001, Accuracy: 348/500 (69%)\n",
      "\n",
      "Train Epoch: 8 [0/5500 (0%)]\tLoss: 0.689834\n",
      "Train Epoch: 8 [1600/5500 (29%)]\tLoss: 1.125667\n",
      "Train Epoch: 8 [3200/5500 (58%)]\tLoss: 0.808297\n",
      "Train Epoch: 8 [4800/5500 (87%)]\tLoss: 0.704956\n",
      "Validation set: Average loss: 0.6421, Accuracy: 350/500 (70%)\n",
      "\n",
      "Train Epoch: 9 [0/5500 (0%)]\tLoss: 0.642656\n",
      "Train Epoch: 9 [1600/5500 (29%)]\tLoss: 0.786292\n",
      "Train Epoch: 9 [3200/5500 (58%)]\tLoss: 0.743480\n",
      "Train Epoch: 9 [4800/5500 (87%)]\tLoss: 0.618314\n",
      "Validation set: Average loss: 0.6313, Accuracy: 356/500 (71%)\n",
      "\n",
      "Train Epoch: 10 [0/5500 (0%)]\tLoss: 0.738029\n",
      "Train Epoch: 10 [1600/5500 (29%)]\tLoss: 0.519295\n",
      "Train Epoch: 10 [3200/5500 (58%)]\tLoss: 0.912110\n",
      "Train Epoch: 10 [4800/5500 (87%)]\tLoss: 0.510618\n",
      "Validation set: Average loss: 0.6520, Accuracy: 349/500 (69%)\n",
      "\n",
      "Train Epoch: 11 [0/5500 (0%)]\tLoss: 0.759313\n",
      "Train Epoch: 11 [1600/5500 (29%)]\tLoss: 0.551546\n",
      "Train Epoch: 11 [3200/5500 (58%)]\tLoss: 0.541904\n",
      "Train Epoch: 11 [4800/5500 (87%)]\tLoss: 0.523505\n",
      "Validation set: Average loss: 0.6362, Accuracy: 354/500 (70%)\n",
      "\n",
      "Train Epoch: 12 [0/5500 (0%)]\tLoss: 0.590999\n",
      "Train Epoch: 12 [1600/5500 (29%)]\tLoss: 0.880165\n",
      "Train Epoch: 12 [3200/5500 (58%)]\tLoss: 0.681836\n",
      "Train Epoch: 12 [4800/5500 (87%)]\tLoss: 0.512696\n",
      "Validation set: Average loss: 0.6518, Accuracy: 357/500 (71%)\n",
      "\n",
      "Train Epoch: 13 [0/5500 (0%)]\tLoss: 0.459955\n",
      "Train Epoch: 13 [1600/5500 (29%)]\tLoss: 0.480095\n",
      "Train Epoch: 13 [3200/5500 (58%)]\tLoss: 1.209942\n",
      "Train Epoch: 13 [4800/5500 (87%)]\tLoss: 0.663633\n",
      "Validation set: Average loss: 0.6222, Accuracy: 366/500 (73%)\n",
      "\n",
      "Train Epoch: 14 [0/5500 (0%)]\tLoss: 0.210981\n",
      "Train Epoch: 14 [1600/5500 (29%)]\tLoss: 0.686798\n",
      "Train Epoch: 14 [3200/5500 (58%)]\tLoss: 0.557578\n",
      "Train Epoch: 14 [4800/5500 (87%)]\tLoss: 0.532769\n",
      "Validation set: Average loss: 0.5896, Accuracy: 359/500 (71%)\n",
      "\n",
      "Train Epoch: 15 [0/5500 (0%)]\tLoss: 0.740398\n",
      "Train Epoch: 15 [1600/5500 (29%)]\tLoss: 0.750103\n",
      "Train Epoch: 15 [3200/5500 (58%)]\tLoss: 0.445716\n",
      "Train Epoch: 15 [4800/5500 (87%)]\tLoss: 0.479412\n",
      "Validation set: Average loss: 0.6087, Accuracy: 364/500 (72%)\n",
      "\n",
      "Train Epoch: 16 [0/5500 (0%)]\tLoss: 0.458764\n",
      "Train Epoch: 16 [1600/5500 (29%)]\tLoss: 0.409622\n",
      "Train Epoch: 16 [3200/5500 (58%)]\tLoss: 0.447069\n",
      "Train Epoch: 16 [4800/5500 (87%)]\tLoss: 0.953053\n",
      "Validation set: Average loss: 0.5864, Accuracy: 372/500 (74%)\n",
      "\n",
      "Train Epoch: 17 [0/5500 (0%)]\tLoss: 0.614678\n",
      "Train Epoch: 17 [1600/5500 (29%)]\tLoss: 0.395919\n",
      "Train Epoch: 17 [3200/5500 (58%)]\tLoss: 0.472152\n",
      "Train Epoch: 17 [4800/5500 (87%)]\tLoss: 0.844798\n",
      "Validation set: Average loss: 0.5740, Accuracy: 373/500 (74%)\n",
      "\n",
      "Train Epoch: 18 [0/5500 (0%)]\tLoss: 0.359054\n",
      "Train Epoch: 18 [1600/5500 (29%)]\tLoss: 0.748733\n",
      "Train Epoch: 18 [3200/5500 (58%)]\tLoss: 0.618872\n",
      "Train Epoch: 18 [4800/5500 (87%)]\tLoss: 0.319037\n",
      "Validation set: Average loss: 0.5886, Accuracy: 366/500 (73%)\n",
      "\n",
      "Train Epoch: 19 [0/5500 (0%)]\tLoss: 0.690313\n",
      "Train Epoch: 19 [1600/5500 (29%)]\tLoss: 0.477237\n",
      "Train Epoch: 19 [3200/5500 (58%)]\tLoss: 0.495193\n",
      "Train Epoch: 19 [4800/5500 (87%)]\tLoss: 0.823204\n",
      "Validation set: Average loss: 0.5636, Accuracy: 380/500 (76%)\n",
      "\n",
      "Train Epoch: 20 [0/5500 (0%)]\tLoss: 0.695768\n",
      "Train Epoch: 20 [1600/5500 (29%)]\tLoss: 0.466170\n",
      "Train Epoch: 20 [3200/5500 (58%)]\tLoss: 0.613339\n",
      "Train Epoch: 20 [4800/5500 (87%)]\tLoss: 0.365617\n",
      "Validation set: Average loss: 0.5787, Accuracy: 373/500 (74%)\n",
      "\n",
      "Train Epoch: 21 [0/5500 (0%)]\tLoss: 0.179207\n",
      "Train Epoch: 21 [1600/5500 (29%)]\tLoss: 0.611962\n",
      "Train Epoch: 21 [3200/5500 (58%)]\tLoss: 0.511720\n",
      "Train Epoch: 21 [4800/5500 (87%)]\tLoss: 0.779880\n",
      "Validation set: Average loss: 0.5750, Accuracy: 366/500 (73%)\n",
      "\n",
      "Train Epoch: 22 [0/5500 (0%)]\tLoss: 0.594676\n",
      "Train Epoch: 22 [1600/5500 (29%)]\tLoss: 0.731227\n",
      "Train Epoch: 22 [3200/5500 (58%)]\tLoss: 0.947283\n",
      "Train Epoch: 22 [4800/5500 (87%)]\tLoss: 0.200389\n",
      "Validation set: Average loss: 0.5591, Accuracy: 371/500 (74%)\n",
      "\n",
      "Train Epoch: 23 [0/5500 (0%)]\tLoss: 0.417219\n",
      "Train Epoch: 23 [1600/5500 (29%)]\tLoss: 0.429052\n",
      "Train Epoch: 23 [3200/5500 (58%)]\tLoss: 1.280607\n",
      "Train Epoch: 23 [4800/5500 (87%)]\tLoss: 0.388623\n",
      "Validation set: Average loss: 0.5603, Accuracy: 365/500 (73%)\n",
      "\n",
      "Train Epoch: 24 [0/5500 (0%)]\tLoss: 0.144758\n",
      "Train Epoch: 24 [1600/5500 (29%)]\tLoss: 0.690036\n",
      "Train Epoch: 24 [3200/5500 (58%)]\tLoss: 1.282193\n",
      "Train Epoch: 24 [4800/5500 (87%)]\tLoss: 0.737592\n",
      "Validation set: Average loss: 0.5686, Accuracy: 372/500 (74%)\n",
      "\n",
      "Train Epoch: 25 [0/5500 (0%)]\tLoss: 0.449902\n",
      "Train Epoch: 25 [1600/5500 (29%)]\tLoss: 0.348280\n",
      "Train Epoch: 25 [3200/5500 (58%)]\tLoss: 0.484333\n",
      "Train Epoch: 25 [4800/5500 (87%)]\tLoss: 0.510918\n",
      "Validation set: Average loss: 0.6068, Accuracy: 381/500 (76%)\n",
      "\n",
      "Train Epoch: 26 [0/5500 (0%)]\tLoss: 0.898502\n",
      "Train Epoch: 26 [1600/5500 (29%)]\tLoss: 0.554062\n",
      "Train Epoch: 26 [3200/5500 (58%)]\tLoss: 0.389530\n",
      "Train Epoch: 26 [4800/5500 (87%)]\tLoss: 0.340219\n",
      "Validation set: Average loss: 0.5978, Accuracy: 373/500 (74%)\n",
      "\n",
      "Train Epoch: 27 [0/5500 (0%)]\tLoss: 0.367307\n",
      "Train Epoch: 27 [1600/5500 (29%)]\tLoss: 0.267261\n",
      "Train Epoch: 27 [3200/5500 (58%)]\tLoss: 0.277448\n",
      "Train Epoch: 27 [4800/5500 (87%)]\tLoss: 0.577880\n",
      "Validation set: Average loss: 0.5658, Accuracy: 383/500 (76%)\n",
      "\n",
      "Train Epoch: 28 [0/5500 (0%)]\tLoss: 0.426888\n",
      "Train Epoch: 28 [1600/5500 (29%)]\tLoss: 0.677329\n",
      "Train Epoch: 28 [3200/5500 (58%)]\tLoss: 0.434955\n",
      "Train Epoch: 28 [4800/5500 (87%)]\tLoss: 0.894680\n",
      "Validation set: Average loss: 0.5535, Accuracy: 364/500 (72%)\n",
      "\n",
      "Train Epoch: 29 [0/5500 (0%)]\tLoss: 0.450896\n",
      "Train Epoch: 29 [1600/5500 (29%)]\tLoss: 0.405198\n",
      "Train Epoch: 29 [3200/5500 (58%)]\tLoss: 0.798007\n",
      "Train Epoch: 29 [4800/5500 (87%)]\tLoss: 0.508745\n",
      "Validation set: Average loss: 0.5545, Accuracy: 372/500 (74%)\n",
      "\n",
      "Train Epoch: 30 [0/5500 (0%)]\tLoss: 0.825088\n",
      "Train Epoch: 30 [1600/5500 (29%)]\tLoss: 0.393630\n",
      "Train Epoch: 30 [3200/5500 (58%)]\tLoss: 0.600473\n",
      "Train Epoch: 30 [4800/5500 (87%)]\tLoss: 0.058820\n",
      "Validation set: Average loss: 0.5543, Accuracy: 372/500 (74%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(net2,optimizer2,epoch)\n",
    "    evaluate(net2,optimizer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:25:16.409248Z",
     "start_time": "2018-05-19T14:25:16.406759Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer3 = optim.Adam(net3.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:31:33.905614Z",
     "start_time": "2018-05-19T14:25:16.410607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/5500 (0%)]\tLoss: 1.141929\n",
      "Train Epoch: 1 [1600/5500 (29%)]\tLoss: 1.003438\n",
      "Train Epoch: 1 [3200/5500 (58%)]\tLoss: 0.996973\n",
      "Train Epoch: 1 [4800/5500 (87%)]\tLoss: 1.109048\n",
      "Validation set: Average loss: 0.9752, Accuracy: 250/500 (50%)\n",
      "\n",
      "Train Epoch: 2 [0/5500 (0%)]\tLoss: 1.082916\n",
      "Train Epoch: 2 [1600/5500 (29%)]\tLoss: 0.847367\n",
      "Train Epoch: 2 [3200/5500 (58%)]\tLoss: 1.003161\n",
      "Train Epoch: 2 [4800/5500 (87%)]\tLoss: 0.907822\n",
      "Validation set: Average loss: 0.8675, Accuracy: 277/500 (55%)\n",
      "\n",
      "Train Epoch: 3 [0/5500 (0%)]\tLoss: 0.571546\n",
      "Train Epoch: 3 [1600/5500 (29%)]\tLoss: 0.704206\n",
      "Train Epoch: 3 [3200/5500 (58%)]\tLoss: 0.779573\n",
      "Train Epoch: 3 [4800/5500 (87%)]\tLoss: 1.065282\n",
      "Validation set: Average loss: 0.8363, Accuracy: 308/500 (61%)\n",
      "\n",
      "Train Epoch: 4 [0/5500 (0%)]\tLoss: 0.793424\n",
      "Train Epoch: 4 [1600/5500 (29%)]\tLoss: 0.709719\n",
      "Train Epoch: 4 [3200/5500 (58%)]\tLoss: 0.694833\n",
      "Train Epoch: 4 [4800/5500 (87%)]\tLoss: 1.018618\n",
      "Validation set: Average loss: 0.7730, Accuracy: 315/500 (63%)\n",
      "\n",
      "Train Epoch: 5 [0/5500 (0%)]\tLoss: 0.339207\n",
      "Train Epoch: 5 [1600/5500 (29%)]\tLoss: 0.885450\n",
      "Train Epoch: 5 [3200/5500 (58%)]\tLoss: 0.693548\n",
      "Train Epoch: 5 [4800/5500 (87%)]\tLoss: 0.581236\n",
      "Validation set: Average loss: 0.7156, Accuracy: 331/500 (66%)\n",
      "\n",
      "Train Epoch: 6 [0/5500 (0%)]\tLoss: 0.562504\n",
      "Train Epoch: 6 [1600/5500 (29%)]\tLoss: 0.912757\n",
      "Train Epoch: 6 [3200/5500 (58%)]\tLoss: 0.735111\n",
      "Train Epoch: 6 [4800/5500 (87%)]\tLoss: 0.701453\n",
      "Validation set: Average loss: 0.7287, Accuracy: 325/500 (65%)\n",
      "\n",
      "Train Epoch: 7 [0/5500 (0%)]\tLoss: 0.858496\n",
      "Train Epoch: 7 [1600/5500 (29%)]\tLoss: 0.600352\n",
      "Train Epoch: 7 [3200/5500 (58%)]\tLoss: 0.617420\n",
      "Train Epoch: 7 [4800/5500 (87%)]\tLoss: 0.316131\n",
      "Validation set: Average loss: 0.7013, Accuracy: 333/500 (66%)\n",
      "\n",
      "Train Epoch: 8 [0/5500 (0%)]\tLoss: 0.741026\n",
      "Train Epoch: 8 [1600/5500 (29%)]\tLoss: 0.818328\n",
      "Train Epoch: 8 [3200/5500 (58%)]\tLoss: 0.558466\n",
      "Train Epoch: 8 [4800/5500 (87%)]\tLoss: 0.597885\n",
      "Validation set: Average loss: 0.6810, Accuracy: 342/500 (68%)\n",
      "\n",
      "Train Epoch: 9 [0/5500 (0%)]\tLoss: 0.543605\n",
      "Train Epoch: 9 [1600/5500 (29%)]\tLoss: 0.998798\n",
      "Train Epoch: 9 [3200/5500 (58%)]\tLoss: 0.386187\n",
      "Train Epoch: 9 [4800/5500 (87%)]\tLoss: 0.506165\n",
      "Validation set: Average loss: 0.7396, Accuracy: 334/500 (66%)\n",
      "\n",
      "Train Epoch: 10 [0/5500 (0%)]\tLoss: 0.563450\n",
      "Train Epoch: 10 [1600/5500 (29%)]\tLoss: 0.706332\n",
      "Train Epoch: 10 [3200/5500 (58%)]\tLoss: 0.795799\n",
      "Train Epoch: 10 [4800/5500 (87%)]\tLoss: 0.707147\n",
      "Validation set: Average loss: 0.6771, Accuracy: 360/500 (72%)\n",
      "\n",
      "Train Epoch: 11 [0/5500 (0%)]\tLoss: 0.645811\n",
      "Train Epoch: 11 [1600/5500 (29%)]\tLoss: 0.575186\n",
      "Train Epoch: 11 [3200/5500 (58%)]\tLoss: 0.521895\n",
      "Train Epoch: 11 [4800/5500 (87%)]\tLoss: 0.806495\n",
      "Validation set: Average loss: 0.6617, Accuracy: 347/500 (69%)\n",
      "\n",
      "Train Epoch: 12 [0/5500 (0%)]\tLoss: 0.534475\n",
      "Train Epoch: 12 [1600/5500 (29%)]\tLoss: 0.323166\n",
      "Train Epoch: 12 [3200/5500 (58%)]\tLoss: 0.331038\n",
      "Train Epoch: 12 [4800/5500 (87%)]\tLoss: 0.499325\n",
      "Validation set: Average loss: 0.6357, Accuracy: 350/500 (70%)\n",
      "\n",
      "Train Epoch: 13 [0/5500 (0%)]\tLoss: 0.406521\n",
      "Train Epoch: 13 [1600/5500 (29%)]\tLoss: 0.454774\n",
      "Train Epoch: 13 [3200/5500 (58%)]\tLoss: 0.655932\n",
      "Train Epoch: 13 [4800/5500 (87%)]\tLoss: 0.326384\n",
      "Validation set: Average loss: 0.6535, Accuracy: 350/500 (70%)\n",
      "\n",
      "Train Epoch: 14 [0/5500 (0%)]\tLoss: 0.482983\n",
      "Train Epoch: 14 [1600/5500 (29%)]\tLoss: 0.424093\n",
      "Train Epoch: 14 [3200/5500 (58%)]\tLoss: 1.064571\n",
      "Train Epoch: 14 [4800/5500 (87%)]\tLoss: 0.489903\n",
      "Validation set: Average loss: 0.6160, Accuracy: 358/500 (71%)\n",
      "\n",
      "Train Epoch: 15 [0/5500 (0%)]\tLoss: 0.704451\n",
      "Train Epoch: 15 [1600/5500 (29%)]\tLoss: 0.694984\n",
      "Train Epoch: 15 [3200/5500 (58%)]\tLoss: 0.523598\n",
      "Train Epoch: 15 [4800/5500 (87%)]\tLoss: 0.446049\n",
      "Validation set: Average loss: 0.6294, Accuracy: 345/500 (69%)\n",
      "\n",
      "Train Epoch: 16 [0/5500 (0%)]\tLoss: 0.609910\n",
      "Train Epoch: 16 [1600/5500 (29%)]\tLoss: 0.866353\n",
      "Train Epoch: 16 [3200/5500 (58%)]\tLoss: 1.025523\n",
      "Train Epoch: 16 [4800/5500 (87%)]\tLoss: 0.420068\n",
      "Validation set: Average loss: 0.6130, Accuracy: 358/500 (71%)\n",
      "\n",
      "Train Epoch: 17 [0/5500 (0%)]\tLoss: 0.509707\n",
      "Train Epoch: 17 [1600/5500 (29%)]\tLoss: 0.718352\n",
      "Train Epoch: 17 [3200/5500 (58%)]\tLoss: 0.688662\n",
      "Train Epoch: 17 [4800/5500 (87%)]\tLoss: 1.064784\n",
      "Validation set: Average loss: 0.5689, Accuracy: 368/500 (73%)\n",
      "\n",
      "Train Epoch: 18 [0/5500 (0%)]\tLoss: 0.226471\n",
      "Train Epoch: 18 [1600/5500 (29%)]\tLoss: 0.342425\n",
      "Train Epoch: 18 [3200/5500 (58%)]\tLoss: 0.353077\n",
      "Train Epoch: 18 [4800/5500 (87%)]\tLoss: 0.723458\n",
      "Validation set: Average loss: 0.5618, Accuracy: 379/500 (75%)\n",
      "\n",
      "Train Epoch: 19 [0/5500 (0%)]\tLoss: 0.500284\n",
      "Train Epoch: 19 [1600/5500 (29%)]\tLoss: 0.344311\n",
      "Train Epoch: 19 [3200/5500 (58%)]\tLoss: 0.744017\n",
      "Train Epoch: 19 [4800/5500 (87%)]\tLoss: 0.319053\n",
      "Validation set: Average loss: 0.5687, Accuracy: 365/500 (73%)\n",
      "\n",
      "Train Epoch: 20 [0/5500 (0%)]\tLoss: 0.828083\n",
      "Train Epoch: 20 [1600/5500 (29%)]\tLoss: 0.664399\n",
      "Train Epoch: 20 [3200/5500 (58%)]\tLoss: 0.619325\n",
      "Train Epoch: 20 [4800/5500 (87%)]\tLoss: 0.568439\n",
      "Validation set: Average loss: 0.6052, Accuracy: 355/500 (71%)\n",
      "\n",
      "Train Epoch: 21 [0/5500 (0%)]\tLoss: 0.498394\n",
      "Train Epoch: 21 [1600/5500 (29%)]\tLoss: 0.534169\n",
      "Train Epoch: 21 [3200/5500 (58%)]\tLoss: 0.713215\n",
      "Train Epoch: 21 [4800/5500 (87%)]\tLoss: 0.494753\n",
      "Validation set: Average loss: 0.6528, Accuracy: 349/500 (69%)\n",
      "\n",
      "Train Epoch: 22 [0/5500 (0%)]\tLoss: 0.998945\n",
      "Train Epoch: 22 [1600/5500 (29%)]\tLoss: 0.545366\n",
      "Train Epoch: 22 [3200/5500 (58%)]\tLoss: 0.412265\n",
      "Train Epoch: 22 [4800/5500 (87%)]\tLoss: 0.467046\n",
      "Validation set: Average loss: 0.5477, Accuracy: 378/500 (75%)\n",
      "\n",
      "Train Epoch: 23 [0/5500 (0%)]\tLoss: 0.529656\n",
      "Train Epoch: 23 [1600/5500 (29%)]\tLoss: 0.532593\n",
      "Train Epoch: 23 [3200/5500 (58%)]\tLoss: 0.460466\n",
      "Train Epoch: 23 [4800/5500 (87%)]\tLoss: 0.447451\n",
      "Validation set: Average loss: 0.7016, Accuracy: 340/500 (68%)\n",
      "\n",
      "Train Epoch: 24 [0/5500 (0%)]\tLoss: 0.365612\n",
      "Train Epoch: 24 [1600/5500 (29%)]\tLoss: 0.358015\n",
      "Train Epoch: 24 [3200/5500 (58%)]\tLoss: 0.337052\n",
      "Train Epoch: 24 [4800/5500 (87%)]\tLoss: 0.502783\n",
      "Validation set: Average loss: 0.5876, Accuracy: 368/500 (73%)\n",
      "\n",
      "Train Epoch: 25 [0/5500 (0%)]\tLoss: 0.795229\n",
      "Train Epoch: 25 [1600/5500 (29%)]\tLoss: 0.637345\n",
      "Train Epoch: 25 [3200/5500 (58%)]\tLoss: 0.386671\n",
      "Train Epoch: 25 [4800/5500 (87%)]\tLoss: 0.263260\n",
      "Validation set: Average loss: 0.6017, Accuracy: 364/500 (72%)\n",
      "\n",
      "Train Epoch: 26 [0/5500 (0%)]\tLoss: 1.251572\n",
      "Train Epoch: 26 [1600/5500 (29%)]\tLoss: 0.609355\n",
      "Train Epoch: 26 [3200/5500 (58%)]\tLoss: 0.507064\n",
      "Train Epoch: 26 [4800/5500 (87%)]\tLoss: 0.677974\n",
      "Validation set: Average loss: 0.5943, Accuracy: 384/500 (76%)\n",
      "\n",
      "Train Epoch: 27 [0/5500 (0%)]\tLoss: 0.739630\n",
      "Train Epoch: 27 [1600/5500 (29%)]\tLoss: 0.512266\n",
      "Train Epoch: 27 [3200/5500 (58%)]\tLoss: 0.769202\n",
      "Train Epoch: 27 [4800/5500 (87%)]\tLoss: 0.445288\n",
      "Validation set: Average loss: 0.5527, Accuracy: 372/500 (74%)\n",
      "\n",
      "Train Epoch: 28 [0/5500 (0%)]\tLoss: 0.701086\n",
      "Train Epoch: 28 [1600/5500 (29%)]\tLoss: 0.680197\n",
      "Train Epoch: 28 [3200/5500 (58%)]\tLoss: 0.581735\n",
      "Train Epoch: 28 [4800/5500 (87%)]\tLoss: 0.493638\n",
      "Validation set: Average loss: 0.5816, Accuracy: 371/500 (74%)\n",
      "\n",
      "Train Epoch: 29 [0/5500 (0%)]\tLoss: 0.625793\n",
      "Train Epoch: 29 [1600/5500 (29%)]\tLoss: 0.252378\n",
      "Train Epoch: 29 [3200/5500 (58%)]\tLoss: 0.273622\n",
      "Train Epoch: 29 [4800/5500 (87%)]\tLoss: 0.559884\n",
      "Validation set: Average loss: 0.5865, Accuracy: 371/500 (74%)\n",
      "\n",
      "Train Epoch: 30 [0/5500 (0%)]\tLoss: 0.786494\n",
      "Train Epoch: 30 [1600/5500 (29%)]\tLoss: 0.841779\n",
      "Train Epoch: 30 [3200/5500 (58%)]\tLoss: 0.526474\n",
      "Train Epoch: 30 [4800/5500 (87%)]\tLoss: 0.542064\n",
      "Validation set: Average loss: 0.5455, Accuracy: 381/500 (76%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(net3,optimizer3,epoch)\n",
    "    evaluate(net3,optimizer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:47:48.703075Z",
     "start_time": "2018-05-19T14:47:48.688509Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred(pred_dataset,model):\n",
    "    pred_loader = torch.utils.data.DataLoader(pred_dataset,\n",
    "                                          batch_size=8,\n",
    "                                          shuffle=False,\n",
    "                                          **kwargs)\n",
    "    model.eval()\n",
    "    result = np.zeros((len(pred_dataset)))\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(pred_loader):\n",
    "            batch_size = data.size()[0]\n",
    "            data = Variable(data)\n",
    "            output = model(data)\n",
    "            pred_class = output.data.max(1, keepdim=False)[1] # get the index of the max log-probability\n",
    "            #print(pred_class)\n",
    "            result[(i*8):(i*8)+batch_size] = pred_class\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:49:13.546317Z",
     "start_time": "2018-05-19T14:49:13.323623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 86, 117,  97]), array([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pred(pred_dataset,net1)\n",
    "np.histogram(prediction,bins=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:49:29.711245Z",
     "start_time": "2018-05-19T14:49:29.706467Z"
    }
   },
   "outputs": [],
   "source": [
    "# PREDICT prediction FROM test_x\n",
    "\n",
    "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
    "assert prediction.ndim == 1\n",
    "assert prediction.shape[0] == 300\n",
    "\n",
    "# AND SAVE EXACTLY AS SHOWN BELOW\n",
    "np.save('prediction.npy', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
